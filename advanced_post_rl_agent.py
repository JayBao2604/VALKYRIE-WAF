"""
Advanced Post-RL Payload Validator and Optimizer
================================================
Ensures payloads generated by RL/LLM are:
1. SYNTACTICALLY CORRECT - Adheres to attack grammar perfectly
2. FUNCTIONALLY VALID - Can execute the intended attack
3. WAF BYPASS CAPABLE - Evades detection mechanisms
4. PRODUCTION-READY - Safe for real-world testing

Pipeline:
1. Grammar Validation - Strict syntax checking
2. Semantic Analysis - Ensure payload makes sense
3. WAF Evasion Analysis - Check bypass techniques
4. Payload Correction - Fix critical errors while preserving obfuscation
5. Dual Re-scoring - Grammar score + Reward model score
6. Final Validation - Real-world simulation testing
"""

import re
import json
import torch
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, asdict, field
from enum import Enum
from abc import ABC, abstractmethod
import hashlib

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# ENUMS & DATA CLASSES
# ============================================================================

class ValidationLevel(Enum):
    """M·ª©c ƒë·ªô x√°c th·ª±c"""
    CRITICAL = "critical"  # L·ªói kh√¥ng th·ªÉ s·ª≠a
    HIGH = "high"  # L·ªói s·ª≠a ƒë∆∞·ª£c nh∆∞ng ·∫£nh h∆∞·ªüng ƒë·∫øn hi·ªáu qu·∫£
    MEDIUM = "medium"  # C√≥ th·ªÉ s·ª≠a, ·∫£nh h∆∞·ªüng nh·ªè
    LOW = "low"  # Warning nh·ªè


class PayloadQuality(Enum):
    """Ch·∫•t l∆∞·ª£ng payload"""
    EXCELLENT = "excellent"  # Score >= 0.85
    GOOD = "good"  # Score >= 0.70
    ACCEPTABLE = "acceptable"  # Score >= 0.50
    POOR = "poor"  # Score < 0.50


@dataclass
class SyntaxCheck:
    """K·∫øt qu·∫£ ki·ªÉm tra c√∫ ph√°p"""
    is_valid: bool
    errors: List[Tuple[ValidationLevel, str]] = field(default_factory=list)
    critical_errors: int = 0
    high_errors: int = 0
    
    def has_critical_errors(self) -> bool:
        return self.critical_errors > 0
    
    def is_correctable(self) -> bool:
        return self.critical_errors == 0


@dataclass
class WAFEvasionAnalysis:
    """Ph√¢n t√≠ch k·ªπ nƒÉng bypass WAF"""
    has_obfuscation: bool = False
    obfuscation_techniques: List[str] = field(default_factory=list)
    encoding_used: List[str] = field(default_factory=list)
    comment_injection: bool = False
    polyglot_capable: bool = False
    case_variation: bool = False
    unicode_encoding: bool = False
    evasion_score: float = 0.0
    
    def to_dict(self):
        return {
            "has_obfuscation": self.has_obfuscation,
            "obfuscation_techniques": self.obfuscation_techniques,
            "encoding_used": self.encoding_used,
            "comment_injection": self.comment_injection,
            "polyglot_capable": self.polyglot_capable,
            "case_variation": self.case_variation,
            "unicode_encoding": self.unicode_encoding,
            "evasion_score": round(self.evasion_score, 4),
        }


@dataclass
class PayloadQualityScore:
    """ƒêi·ªÉm ch·∫•t l∆∞·ª£ng to√†n di·ªán"""
    grammar_score: float  # 0-1, t·ª´ c√∫ ph√°p
    reward_score: float  # 0-1, t·ª´ reward model
    evasion_score: float  # 0-1, kh·∫£ nƒÉng bypass WAF
    semantic_score: float  # 0-1, c√≥ √Ω nghƒ©a t·∫•n c√¥ng
    combined_score: float  # 0-1, ƒëi·ªÉm t·ªïng h·ª£p
    quality_level: PayloadQuality = PayloadQuality.POOR
    
    def to_dict(self):
        return {
            "grammar_score": round(self.grammar_score, 4),
            "reward_score": round(self.reward_score, 4),
            "evasion_score": round(self.evasion_score, 4),
            "semantic_score": round(self.semantic_score, 4),
            "combined_score": round(self.combined_score, 4),
            "quality_level": self.quality_level.value,
        }


@dataclass
class AdvancedValidationResult:
    """K·∫øt qu·∫£ x√°c th·ª±c chi ti·∫øt"""
    original_payload: str
    corrected_payload: str
    payload_hash: str
    
    # Validation results
    syntax_check: SyntaxCheck
    waf_evasion: WAFEvasionAnalysis
    quality_score: PayloadQualityScore
    
    # Corrections and analysis
    corrections_applied: List[str] = field(default_factory=list)
    semantic_analysis: Dict = field(default_factory=dict)
    
    # Status
    is_production_ready: bool = False
    rejection_reasons: List[str] = field(default_factory=list)
    
    def to_dict(self):
        return {
            "payload_hash": self.payload_hash,
            "original_payload": self.original_payload,
            "corrected_payload": self.corrected_payload,
            "syntax_valid": self.syntax_check.is_valid,
            "syntax_errors": len(self.syntax_check.errors),
            "syntax_details": [
                {"level": err[0].value, "message": err[1]}
                for err in self.syntax_check.errors
            ],
            "waf_evasion": self.waf_evasion.to_dict(),
            "quality_scores": self.quality_score.to_dict(),
            "corrections_applied": self.corrections_applied,
            "semantic_analysis": self.semantic_analysis,
            "is_production_ready": self.is_production_ready,
            "rejection_reasons": self.rejection_reasons,
        }


# ============================================================================
# ADVANCED GRAMMAR VALIDATOR
# ============================================================================

class StrictGrammarValidator:
    """X√°c th·ª±c c√∫ ph√°p nghi√™m ng·∫∑t d·ª±a tr√™n grammar"""
    
    def __init__(self, attack_type: str, grammar_dir: str = "data/grammars"):
        self.attack_type = attack_type
        self.grammar_file = Path(grammar_dir) / f"{attack_type}-grammar.txt"
        self.grammar_rules = self._load_grammar_rules()
        self.required_elements = self._load_required_elements()
        
    def _load_grammar_rules(self) -> Dict[str, List[str]]:
        """Load grammar rules t·ª´ file"""
        rules = {}
        try:
            with open(self.grammar_file, 'r', encoding='utf-8') as f:
                content = f.read()
                for line in content.split('\n'):
                    line = line.strip()
                    if not line or line.startswith("//"):
                        continue
                    if ':' in line and ';' in line:
                        head, body = line.split(':', 1)
                        head = head.strip()
                        body = body.split(';')[0]
                        alternatives = [alt.strip() for alt in body.split('|')]
                        rules[head] = alternatives
            logger.info(f"‚úì Loaded {len(rules)} grammar rules for {self.attack_type}")
        except FileNotFoundError:
            logger.warning(f"Grammar file not found: {self.grammar_file}")
        return rules
    
    def _load_required_elements(self) -> Dict[str, List[str]]:
        """T·∫£i c√°c ph·∫ßn t·ª≠ b·∫Øt bu·ªôc cho t·ª´ng lo·∫°i t·∫•n c√¥ng"""
        requirements = {
            "sqli": {
                "required_keywords": ["select", "union", "where", "or", "and"],
                "must_have_one_of": ["or", "and", "union"],
                "syntax_rules": [
                    ("quote_balance", "C√¢n b·∫±ng quotes"),
                    ("parenthesis_balance", "C√¢n b·∫±ng ngo·∫∑c ƒë∆°n"),
                    ("comment_closure", "ƒê√≥ng comment"),
                ],
            },
            "xss": {
                "required_keywords": ["<", ">"],
                "must_have_one_of": ["<script", "onload", "onerror", "onclick"],
                "syntax_rules": [
                    ("tag_balance", "C√¢n b·∫±ng tags"),
                    ("quote_balance", "C√¢n b·∫±ng quotes trong attributes"),
                    ("script_closure", "ƒê√≥ng script tag"),
                ],
            },
            "rce": {
                "required_keywords": [";", "|", "&"],
                "must_have_one_of": [";", "|", "&", "||", "&&"],
                "syntax_rules": [
                    ("separator_presence", "C√≥ command separator"),
                    ("quote_balance", "C√¢n b·∫±ng quotes"),
                    ("paren_balance", "C√¢n b·∫±ng ngo·∫∑c"),
                ],
            },
            "xxe": {
                "required_keywords": ["<!entity", "<!doctype"],
                "must_have_one_of": ["<!entity", "<!doctype", "<?xml"],
                "syntax_rules": [
                    ("xml_structure", "C·∫•u tr√∫c XML ƒë√∫ng"),
                    ("tag_balance", "C√¢n b·∫±ng tags"),
                    ("entity_closure", "ƒê√≥ng entity"),
                ],
            },
            "ssrf": {
                "required_keywords": ["://"],
                "must_have_one_of": ["http://", "https://", "file://", "ftp://"],
                "syntax_rules": [
                    ("url_format", "ƒê·ªãnh d·∫°ng URL ƒë√∫ng"),
                    ("scheme_presence", "C√≥ URL scheme"),
                ],
            },
            "nosqli": {
                "required_keywords": ["{", "}"],
                "must_have_one_of": ["$where", "$ne", "$gt", "$lt"],
                "syntax_rules": [
                    ("brace_balance", "C√¢n b·∫±ng braces"),
                    ("bracket_balance", "C√¢n b·∫±ng brackets"),
                    ("quote_balance", "C√¢n b·∫±ng quotes"),
                ],
            },
        }
        return requirements.get(self.attack_type, {})
    
    def validate_comprehensive(self, payload: str) -> SyntaxCheck:
        """X√°c th·ª±c to√†n di·ªán payload"""
        check = SyntaxCheck(is_valid=True)
        
        if self.attack_type == "sqli":
            self._validate_sqli_strict(payload, check)
        elif self.attack_type == "xss":
            self._validate_xss_strict(payload, check)
        elif self.attack_type == "rce":
            self._validate_rce_strict(payload, check)
        elif self.attack_type == "xxe":
            self._validate_xxe_strict(payload, check)
        elif self.attack_type == "ssrf":
            self._validate_ssrf_strict(payload, check)
        elif self.attack_type == "nosqli":
            self._validate_nosqli_strict(payload, check)
        
        # T√≠nh s·ªë l·ªói
        check.critical_errors = sum(1 for level, _ in check.errors if level == ValidationLevel.CRITICAL)
        check.high_errors = sum(1 for level, _ in check.errors if level == ValidationLevel.HIGH)
        check.is_valid = check.critical_errors == 0
        
        return check
    
    def _validate_sqli_strict(self, payload: str, check: SyntaxCheck):
        """X√°c th·ª±c SQL Injection nghi√™m ng·∫∑t"""
        lower = payload.lower()
        
        # 1. Ki·ªÉm tra quote balance (CRITICAL)
        single_count = payload.count("'")
        double_count = payload.count('"')
        if single_count > 0 and single_count % 2 != 0 and "%27" not in payload:
            check.errors.append((ValidationLevel.CRITICAL, "Single quote kh√¥ng c√¢n b·∫±ng (kh√¥ng encode)"))
        if double_count % 2 != 0:
            check.errors.append((ValidationLevel.CRITICAL, "Double quote kh√¥ng c√¢n b·∫±ng"))
        
        # 2. Ki·ªÉm tra parenthesis balance (HIGH)
        if payload.count("(") != payload.count(")"):
            check.errors.append((ValidationLevel.HIGH, "Parenthesis kh√¥ng c√¢n b·∫±ng"))
        
        # 3. Ki·ªÉm tra comment closure (HIGH)
        if "/*" in payload and "*/" not in payload:
            check.errors.append((ValidationLevel.HIGH, "Comment block kh√¥ng ƒë√≥ng"))
        
        # 4. Ki·ªÉm tra c√≥ √≠t nh·∫•t m·ªôt injection marker (CRITICAL)
        markers = ["or", "and", "union", "select", "where"]
        has_marker = any(re.search(rf"\b{m}\b", lower) for m in markers)
        if not has_marker:
            check.errors.append((ValidationLevel.CRITICAL, "Kh√¥ng c√≥ SQL injection marker"))
        
        # 5. Ki·ªÉm tra function syntax (HIGH)
        if "sleep(" in lower:
            if not re.search(r"sleep\(\d+\)", payload):
                check.errors.append((ValidationLevel.HIGH, "Sleep function syntax sai"))
        
        # 6. Ki·ªÉm tra query logic (MEDIUM)
        if "1=1" not in payload and "true" not in lower and "1" not in payload:
            check.errors.append((ValidationLevel.MEDIUM, "Query logic kh√¥ng r√µ r√†ng"))
    
    def _validate_xss_strict(self, payload: str, check: SyntaxCheck):
        """X√°c th·ª±c XSS ngh√™m ng·∫∑t"""
        lower = payload.lower()
        
        # 1. Ki·ªÉm tra tag balance (CRITICAL)
        open_tags = len(re.findall(r"<\w+", payload))
        close_tags = len(re.findall(r"</\w+>", payload))
        if open_tags > close_tags + 1:
            check.errors.append((ValidationLevel.CRITICAL, "HTML tag kh√¥ng c√¢n b·∫±ng"))
        
        # 2. Ki·ªÉm tra script tag closure (HIGH)
        if "<script" in lower and "</script>" not in lower:
            check.errors.append((ValidationLevel.HIGH, "Script tag kh√¥ng ƒë√≥ng"))
        
        # 3. Ki·ªÉm tra quote balance trong attributes (HIGH)
        if payload.count('"') % 2 != 0 and payload.count("'") % 2 != 0:
            check.errors.append((ValidationLevel.HIGH, "Quote trong attributes kh√¥ng c√¢n b·∫±ng"))
        
        # 4. Ki·ªÉm tra c√≥ event handler ho·∫∑c script (CRITICAL)
        event_patterns = [
            r"on\w+\s*=", r"<script", r"javascript:", r"onerror", r"onload"
        ]
        has_event = any(re.search(p, payload, re.IGNORECASE) for p in event_patterns)
        if not has_event:
            check.errors.append((ValidationLevel.CRITICAL, "Kh√¥ng c√≥ XSS vector"))
        
        # 5. Ki·ªÉm tra payload closure (HIGH)
        if not (payload.rstrip().endswith(">") or payload.rstrip().endswith(")")):
            check.errors.append((ValidationLevel.HIGH, "Payload kh√¥ng k·∫øt th√∫c ƒë√∫ng"))
    
    def _validate_rce_strict(self, payload: str, check: SyntaxCheck):
        """X√°c th·ª±c RCE nghi√™m ng·∫∑t"""
        
        # 1. Ki·ªÉm tra command separator (CRITICAL)
        separators = [";", "|", "&", "||", "&&"]
        has_sep = any(sep in payload for sep in separators)
        if not has_sep and "${" not in payload and "$(" not in payload:
            check.errors.append((ValidationLevel.CRITICAL, "Kh√¥ng c√≥ command separator"))
        
        # 2. Ki·ªÉm tra quote balance (HIGH)
        if payload.count('"') % 2 != 0 and payload.count("'") % 2 != 0:
            check.errors.append((ValidationLevel.HIGH, "Quote kh√¥ng c√¢n b·∫±ng"))
        
        # 3. Ki·ªÉm tra command substitution closure (HIGH)
        if "$(" in payload and ")" not in payload:
            check.errors.append((ValidationLevel.HIGH, "Command substitution kh√¥ng ƒë√≥ng"))
        
        # 4. Ki·ªÉm tra brace balance (HIGH)
        if "${" in payload and payload.count("{") != payload.count("}"):
            check.errors.append((ValidationLevel.HIGH, "Brace kh√¥ng c√¢n b·∫±ng"))
    
    def _validate_xxe_strict(self, payload: str, check: SyntaxCheck):
        """X√°c th·ª±c XXE ngh√™m ng·∫∑t"""
        lower = payload.lower()
        
        # 1. Ki·ªÉm tra XML declaration ho·∫∑c entity (CRITICAL)
        if not re.search(r"<!\w+|<\?xml", lower):
            check.errors.append((ValidationLevel.CRITICAL, "Kh√¥ng c√≥ XML declaration"))
        
        # 2. Ki·ªÉm tra tag balance (CRITICAL)
        if payload.count("<") != payload.count(">"):
            check.errors.append((ValidationLevel.CRITICAL, "XML tag kh√¥ng c√¢n b·∫±ng"))
        
        # 3. Ki·ªÉm tra entity closure (HIGH)
        upper_payload = payload.upper()
        if "<!ENTITY" in upper_payload:
            entity_start = payload.find("<!ENTITY")
            if ">" not in payload[entity_start:entity_start+100]:
                check.errors.append((ValidationLevel.HIGH, "Entity declaration kh√¥ng ƒë√≥ng"))
    
    def _validate_ssrf_strict(self, payload: str, check: SyntaxCheck):
        """X√°c th·ª±c SSRF nghi√™m ng·∫∑t"""
        lower = payload.lower()
        
        # 1. Ki·ªÉm tra URL scheme (CRITICAL)
        schemes = ["http://", "https://", "file://", "ftp://", "gopher://"]
        has_scheme = any(lower.startswith(s) for s in schemes)
        if not has_scheme:
            check.errors.append((ValidationLevel.CRITICAL, "Kh√¥ng c√≥ valid URL scheme"))
        
        # 2. Ki·ªÉm tra URL format (HIGH)
        if not re.match(r"[a-z]+://", lower):
            check.errors.append((ValidationLevel.HIGH, "Invalid URL format"))
    
    def _validate_nosqli_strict(self, payload: str, check: SyntaxCheck):
        """X√°c th·ª±c NoSQL Injection nghi√™m ng·∫∑t"""
        
        # 1. Ki·ªÉm tra brace balance (CRITICAL)
        if payload.count("{") != payload.count("}"):
            check.errors.append((ValidationLevel.CRITICAL, "Brace kh√¥ng c√¢n b·∫±ng"))
        
        # 2. Ki·ªÉm tra bracket balance (HIGH)
        if payload.count("[") != payload.count("]"):
            check.errors.append((ValidationLevel.HIGH, "Bracket kh√¥ng c√¢n b·∫±ng"))
        
        # 3. Ki·ªÉm tra quote balance (HIGH)
        if payload.count('"') % 2 != 0:
            check.errors.append((ValidationLevel.HIGH, "Quote kh√¥ng c√¢n b·∫±ng"))


# ============================================================================
# WAF EVASION ANALYZER
# ============================================================================

class WAFEvasionAnalyzer:
    """Ph√¢n t√≠ch kh·∫£ nƒÉng bypass WAF"""
    
    def __init__(self, attack_type: str):
        self.attack_type = attack_type
        self.evasion_techniques = self._load_evasion_techniques()
    
    def _load_evasion_techniques(self) -> Dict[str, List[Tuple[str, str]]]:
        """Load k·ªπ thu·∫≠t evasion cho t·ª´ng lo·∫°i t·∫•n c√¥ng"""
        return {
            "sqli": [
                (r"%27", "Single quote encoding (URL)"),
                (r"%22", "Double quote encoding"),
                (r"%2F", "Slash encoding"),
                (r"/\*.*?\*/", "Comment injection"),
                (r"(?i)\b(select|union|where)\b", "Case variation"),
                (r"\+", "Plus as space"),
                (r"%0b", "Vertical tab whitespace"),
                (r"0x", "Hex encoding"),
            ],
            "xss": [
                (r"%3c", "< encoding"),
                (r"%3e", "> encoding"),
                (r"&#", "HTML entity encoding"),
                (r"\\x[0-9a-fA-F]", "Hex escape"),
                (r"\\u[0-9a-fA-F]", "Unicode escape"),
                (r"<\s*script", "Space in tag"),
                (r"(?i)<SCRIPT", "Case variation"),
                (r"on\w+\s*=", "Event handler"),
            ],
            "rce": [
                (r"'\\+['\"]", "String concatenation"),
                (r"base64", "Base64 encoding"),
                (r"\$\{.*?\}", "Variable substitution"),
                (r"\$\(.*?\)", "Command substitution"),
                (r"IFS", "IFS bypass"),
                (r"\\x[0-9a-fA-F]", "Hex encoding"),
            ],
            "xxe": [
                (r"&#\d+;", "HTML entity"),
                (r"\\x[0-9a-fA-F]", "Hex encoding"),
                (r"SYSTEM", "External entity"),
                (r"%", "Parameter entity"),
            ],
            "ssrf": [
                (r"127\.1", "IP shorthand"),
                (r"0x7f000001", "Hex IP"),
                (r"@", "User separator bypass"),
                (r"#", "Fragment bypass"),
                (r"\?", "Query string bypass"),
            ],
        }
    
    def analyze(self, payload: str) -> WAFEvasionAnalysis:
        """Ph√¢n t√≠ch k·ªπ nƒÉng evasion c·ªßa payload"""
        analysis = WAFEvasionAnalysis()
        techniques = self.evasion_techniques.get(self.attack_type, [])
        
        for pattern, technique_name in techniques:
            if re.search(pattern, payload, re.IGNORECASE):
                analysis.obfuscation_techniques.append(technique_name)
                analysis.has_obfuscation = True
                
                # Classify technique
                if "encoding" in technique_name.lower():
                    analysis.encoding_used.append(technique_name)
                if "comment" in technique_name.lower():
                    analysis.comment_injection = True
                if "case" in technique_name.lower() or "variation" in technique_name.lower():
                    analysis.case_variation = True
                if "unicode" in technique_name.lower() or "escape" in technique_name.lower():
                    analysis.unicode_encoding = True
        
        # Calculate evasion score
        analysis.evasion_score = min(len(analysis.obfuscation_techniques) * 0.15, 0.8)
        
        # Check polyglot capability
        if self.attack_type == "sqli":
            analysis.polyglot_capable = any(
                tech in analysis.obfuscation_techniques 
                for tech in ["Comment injection", "Case variation"]
            )
        
        return analysis


# ============================================================================
# SEMANTIC ANALYZER
# ============================================================================

class SemanticAnalyzer:
    """Ph√¢n t√≠ch √Ω nghƒ©a t·∫•n c√¥ng c·ªßa payload"""
    
    def __init__(self, attack_type: str):
        self.attack_type = attack_type
        self.attack_patterns = self._load_attack_patterns()
    
    def _load_attack_patterns(self) -> Dict[str, Dict]:
        """Load c√°c m·∫´u t·∫•n c√¥ng t·ª´ng lo·∫°i"""
        return {
            "sqli": {
                "boolean_based": [
                    r"(?i)\b(or|and)\s+\d+\s*=\s*\d+",
                    r"(?i)\b(or|and)\s+['\"]{0,1}true['\"]{0,1}",
                ],
                "union_based": [
                    r"(?i)\bunion\b.*?\bselect\b",
                ],
                "time_based": [
                    r"(?i)sleep\(\d+\)",
                    r"(?i)benchmark\(",
                ],
                "error_based": [
                    r"(?i)extractvalue",
                    r"(?i)updatexml",
                ],
            },
            "xss": {
                "dom_based": [r"document\.", r"innerHTML", r"addEventListener"],
                "reflected": [r"<script", r"alert\("],
                "stored": [r"eval\(", r"Function\("],
            },
            "rce": {
                "command_exec": [r"(?i)exec|system|shell_exec|passthru"],
                "command_injection": [r"[;|&]\s*(?i)(cat|ls|whoami)"],
            },
        }
    
    def analyze(self, payload: str) -> Dict:
        """Ph√¢n t√≠ch √Ω nghƒ©a payload"""
        analysis = {
            "attack_type": self.attack_type,
            "detected_methods": [],
            "data_extraction_capable": False,
            "command_execution_capable": False,
            "semantic_score": 0.5,
        }
        
        patterns = self.attack_patterns.get(self.attack_type, {})
        for method, pattern_list in patterns.items():
            for pattern in pattern_list:
                if re.search(pattern, payload, re.IGNORECASE):
                    analysis["detected_methods"].append(method)
        
        # ƒê√°nh gi√° kh·∫£ nƒÉng
        if self.attack_type == "sqli":
            analysis["data_extraction_capable"] = any(
                m in analysis["detected_methods"] 
                for m in ["boolean_based", "union_based", "error_based"]
            )
            analysis["semantic_score"] = min(
                0.5 + len(analysis["detected_methods"]) * 0.2, 1.0
            )
        elif self.attack_type == "rce":
            analysis["command_execution_capable"] = len(analysis["detected_methods"]) > 0
            analysis["semantic_score"] = min(
                0.5 + len(analysis["detected_methods"]) * 0.25, 1.0
            )
        
        return analysis


# ============================================================================
# INTELLIGENT PAYLOAD CORRECTOR
# ============================================================================

class IntelligentPayloadCorrector:
    """S·ª≠a l·ªói payload th√¥ng minh"""
    
    def __init__(self, grammar_validator: StrictGrammarValidator):
        self.validator = grammar_validator
    
    def correct_critical_errors(self, payload: str, errors: List) -> Tuple[str, List[str]]:
        """S·ª≠a CH·ªà c√°c l·ªói CRITICAL"""
        corrected = payload
        corrections = []
        
        critical_errors = [e for e in errors if e[0] == ValidationLevel.CRITICAL]
        
        for level, error_msg in critical_errors:
            if "quote" in error_msg.lower() and "single" in error_msg.lower():
                corrected, fixed = self._fix_unbalanced_single_quote(corrected)
                if fixed:
                    corrections.append("Fixed: Unbalanced single quote")
            
            elif "quote" in error_msg.lower() and "double" in error_msg.lower():
                corrected, fixed = self._fix_unbalanced_double_quote(corrected)
                if fixed:
                    corrections.append("Fixed: Unbalanced double quote")
            
            elif "tag" in error_msg.lower():
                corrected, fixed = self._fix_unbalanced_tags(corrected)
                if fixed:
                    corrections.append("Fixed: Unbalanced tags")
            
            elif "brace" in error_msg.lower():
                corrected, fixed = self._fix_unbalanced_braces(corrected)
                if fixed:
                    corrections.append("Fixed: Unbalanced braces")
            
            elif "marker" in error_msg.lower() or "vector" in error_msg.lower():
                # Cannot auto-fix missing attack vector
                pass
        
        return corrected, corrections
    
    def _fix_unbalanced_single_quote(self, payload: str) -> Tuple[str, bool]:
        """Fix unbalanced single quote"""
        if "%27" in payload:
            return payload, False
        count = payload.count("'")
        if count % 2 != 0:
            return payload + "'", True
        return payload, False
    
    def _fix_unbalanced_double_quote(self, payload: str) -> Tuple[str, bool]:
        """Fix unbalanced double quote"""
        if "%22" in payload:
            return payload, False
        count = payload.count('"')
        if count % 2 != 0:
            return payload + '"', True
        return payload, False
    
    def _fix_unbalanced_tags(self, payload: str) -> Tuple[str, bool]:
        """Fix unbalanced HTML/XML tags"""
        open_tags = re.findall(r"<(\w+)", payload)
        close_tags = re.findall(r"</(\w+)>", payload)
        
        for tag in open_tags:
            if tag not in close_tags:
                payload += f"</{tag}>"
                return payload, True
        return payload, False
    
    def _fix_unbalanced_braces(self, payload: str) -> Tuple[str, bool]:
        """Fix unbalanced braces"""
        open_count = payload.count("{")
        close_count = payload.count("}")
        
        if open_count > close_count:
            return payload + "}" * (open_count - close_count), True
        return payload, False


# ============================================================================
# REWARD EVALUATOR
# ============================================================================

class AdvancedRewardEvaluator:
    """ƒê√°nh gi√° payload s·ª≠ d·ª•ng reward model"""
    
    def __init__(self, attack_type: str, model_path: str = None, device: str = "cpu"):
        self.attack_type = attack_type
        self.device = torch.device(device)
        self.model = None
        self.tokenizer = None
        
        if model_path:
            self._load_model(model_path)
    
    def _load_model(self, model_path: str):
        """Load reward model"""
        try:
            from transformers import AutoTokenizer, AutoModelForSequenceClassification
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
            self.model.to(self.device)
            self.model.eval()
            logger.info(f"‚úì Loaded reward model: {model_path}")
        except Exception as e:
            logger.warning(f"Failed to load reward model: {e}")
    
    def score(self, payload: str) -> float:
        """Score payload using reward model"""
        if self.model is None:
            return self._heuristic_score(payload)
        
        try:
            inputs = self.tokenizer(
                payload,
                return_tensors="pt",
                truncation=True,
                padding="max_length",
                max_length=128,
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                score = torch.sigmoid(logits[0][0]).item() if logits.ndim == 2 else torch.sigmoid(logits[0]).item()
            
            return score
        except Exception as e:
            logger.error(f"Error scoring: {e}")
            return self._heuristic_score(payload)
    
    def _heuristic_score(self, payload: str) -> float:
        """Heuristic scoring"""
        score = 0.5
        
        if 15 < len(payload) < 500:
            score += 0.2
        
        keywords = {
            "sqli": ["select", "union", "where", "or", "and"],
            "xss": ["script", "onclick", "onerror", "alert"],
            "rce": ["bash", "sh", "cmd", "exec"],
        }
        
        kw = keywords.get(self.attack_type, [])
        keyword_count = sum(1 for k in kw if k in payload.lower())
        score += min(keyword_count * 0.08, 0.25)
        
        return min(max(0.0, score), 1.0)


# ============================================================================
# MAIN ADVANCED AGENT
# ============================================================================

class AdvancedPostRLAgent:
    """Agent x√°c th·ª±c payload to√†n di·ªán cho production"""
    
    def __init__(self,
                 attack_type: str,
                 grammar_dir: str = "data/grammars",
                 reward_model_path: str = None,
                 device: str = "cpu",
                 min_combined_score: float = 0.70):
        self.attack_type = attack_type
        self.min_combined_score = min_combined_score
        
        self.grammar_validator = StrictGrammarValidator(attack_type, grammar_dir)
        self.waf_analyzer = WAFEvasionAnalyzer(attack_type)
        self.semantic_analyzer = SemanticAnalyzer(attack_type)
        self.corrector = IntelligentPayloadCorrector(self.grammar_validator)
        self.reward_evaluator = AdvancedRewardEvaluator(attack_type, reward_model_path, device)
        
        self.results: List[AdvancedValidationResult] = []
        logger.info(f"‚úì Initialized AdvancedPostRL Agent for {attack_type}")
    
    def validate_payload(self, payload: str) -> AdvancedValidationResult:
        """Validate payload to√†n di·ªán"""
        
        # Generate hash
        payload_hash = hashlib.sha256(payload.encode()).hexdigest()[:16]
        
        # 1. Grammar validation
        syntax_check = self.grammar_validator.validate_comprehensive(payload)
        
        # 2. Correct critical errors
        corrected_payload = payload
        corrections = []
        if not syntax_check.is_valid:
            corrected_payload, corrections = self.corrector.correct_critical_errors(
                payload, syntax_check.errors
            )
            # Re-validate corrected payload
            syntax_check = self.grammar_validator.validate_comprehensive(corrected_payload)
        
        # 3. WAF evasion analysis
        waf_analysis = self.waf_analyzer.analyze(corrected_payload)
        
        # 4. Semantic analysis
        semantic_analysis = self.semantic_analyzer.analyze(corrected_payload)
        
        # 5. Score payloads
        grammar_score = 1.0 if syntax_check.is_valid else max(0, 1.0 - (syntax_check.critical_errors * 0.3))
        reward_score = self.reward_evaluator.score(corrected_payload)
        evasion_score = waf_analysis.evasion_score
        semantic_score = semantic_analysis.get("semantic_score", 0.5)
        
        # 6. Combine scores
        combined_score = (
            grammar_score * 0.35 +
            reward_score * 0.35 +
            evasion_score * 0.15 +
            semantic_score * 0.15
        )
        
        # Determine quality level
        if combined_score >= 0.85:
            quality = PayloadQuality.EXCELLENT
        elif combined_score >= 0.70:
            quality = PayloadQuality.GOOD
        elif combined_score >= 0.50:
            quality = PayloadQuality.ACCEPTABLE
        else:
            quality = PayloadQuality.POOR
        
        quality_score = PayloadQualityScore(
            grammar_score=grammar_score,
            reward_score=reward_score,
            evasion_score=evasion_score,
            semantic_score=semantic_score,
            combined_score=combined_score,
            quality_level=quality
        )
        
        # 7. Determine production readiness
        is_production_ready = (
            syntax_check.is_valid and
            combined_score >= self.min_combined_score and
            semantic_analysis.get("data_extraction_capable" if self.attack_type == "sqli" else "command_execution_capable", True)
        )
        
        rejection_reasons = []
        if not syntax_check.is_valid:
            rejection_reasons.append(f"Syntax errors: {syntax_check.critical_errors} critical")
        if combined_score < self.min_combined_score:
            rejection_reasons.append(f"Low score: {combined_score:.2f} < {self.min_combined_score}")
        
        result = AdvancedValidationResult(
            original_payload=payload,
            corrected_payload=corrected_payload,
            payload_hash=payload_hash,
            syntax_check=syntax_check,
            waf_evasion=waf_analysis,
            quality_score=quality_score,
            corrections_applied=corrections,
            semantic_analysis=semantic_analysis,
            is_production_ready=is_production_ready,
            rejection_reasons=rejection_reasons,
        )
        
        self.results.append(result)
        return result
    
    def process_batch(self, payloads: List[str], verbose: bool = False) -> List[AdvancedValidationResult]:
        """Process batch of payloads"""
        results = []
        for i, payload in enumerate(payloads, 1):
            if verbose and i % 20 == 0:
                logger.info(f"Processing {i}/{len(payloads)}...")
            result = self.validate_payload(payload)
            results.append(result)
        return results
    
    def export_production_ready(self, output_file: str) -> Dict:
        """Export only production-ready payloads"""
        production_payloads = [r for r in self.results if r.is_production_ready]
        
        export_data = {
            "metadata": {
                "attack_type": self.attack_type,
                "total_processed": len(self.results),
                "production_ready": len(production_payloads),
                "production_rate": round(len(production_payloads) / len(self.results), 4) if self.results else 0,
                "min_combined_score": self.min_combined_score,
            },
            "statistics": self.get_statistics(),
            "payloads": [r.to_dict() for r in production_payloads],
        }
        
        Path(output_file).parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úì Exported {len(production_payloads)} production-ready payloads to {output_file}")
        return export_data
    
    def get_statistics(self) -> Dict:
        """Get validation statistics"""
        if not self.results:
            return {}
        
        total = len(self.results)
        production_ready = sum(1 for r in self.results if r.is_production_ready)
        syntax_valid = sum(1 for r in self.results if r.syntax_check.is_valid)
        excellent = sum(1 for r in self.results if r.quality_score.quality_level == PayloadQuality.EXCELLENT)
        good = sum(1 for r in self.results if r.quality_score.quality_level == PayloadQuality.GOOD)
        acceptable = sum(1 for r in self.results if r.quality_score.quality_level == PayloadQuality.ACCEPTABLE)
        poor = sum(1 for r in self.results if r.quality_score.quality_level == PayloadQuality.POOR)
        
        with_corrections = sum(1 for r in self.results if r.corrections_applied)
        with_evasion = sum(1 for r in self.results if r.waf_evasion.has_obfuscation)
        
        avg_grammar = sum(r.quality_score.grammar_score for r in self.results) / total
        avg_reward = sum(r.quality_score.reward_score for r in self.results) / total
        avg_evasion = sum(r.quality_score.evasion_score for r in self.results) / total
        avg_combined = sum(r.quality_score.combined_score for r in self.results) / total
        
        return {
            "total_payloads": total,
            "production_ready": production_ready,
            "production_rate_percent": round(production_ready / total * 100, 2),
            "syntax_valid": syntax_valid,
            "syntax_valid_rate_percent": round(syntax_valid / total * 100, 2),
            "quality_distribution": {
                "excellent": excellent,
                "good": good,
                "acceptable": acceptable,
                "poor": poor,
            },
            "payloads_with_corrections": with_corrections,
            "payloads_with_evasion": with_evasion,
            "average_scores": {
                "grammar_score": round(avg_grammar, 4),
                "reward_score": round(avg_reward, 4),
                "evasion_score": round(avg_evasion, 4),
                "combined_score": round(avg_combined, 4),
            },
        }
    
    def print_summary(self):
        """Print comprehensive summary"""
        stats = self.get_statistics()
        
        print("\n" + "="*80)
        print("ADVANCED POST-RL PAYLOAD VALIDATION - PRODUCTION READINESS REPORT")
        print("="*80)
        print(f"Attack Type: {self.attack_type.upper()}")
        print(f"\nProcessing Summary:")
        print(f"  Total Payloads: {stats.get('total_payloads', 0)}")
        print(f"  Production Ready: {stats.get('production_ready', 0)} ({stats.get('production_rate_percent', 0):.2f}%)")
        print(f"  Syntax Valid: {stats.get('syntax_valid', 0)} ({stats.get('syntax_valid_rate_percent', 0):.2f}%)")
        
        print(f"\nQuality Distribution:")
        dist = stats.get('quality_distribution', {})
        print(f"  Excellent: {dist.get('excellent', 0)}")
        print(f"  Good: {dist.get('good', 0)}")
        print(f"  Acceptable: {dist.get('acceptable', 0)}")
        print(f"  Poor: {dist.get('poor', 0)}")
        
        print(f"\nOptimizations:")
        print(f"  With Corrections: {stats.get('payloads_with_corrections', 0)}")
        print(f"  With WAF Evasion: {stats.get('payloads_with_evasion', 0)}")
        
        scores = stats.get('average_scores', {})
        print(f"\nAverage Scores:")
        print(f"  Grammar: {scores.get('grammar_score', 0):.4f}")
        print(f"  Reward: {scores.get('reward_score', 0):.4f}")
        print(f"  Evasion: {scores.get('evasion_score', 0):.4f}")
        print(f"  Combined: {scores.get('combined_score', 0):.4f}")
        print("="*80 + "\n")


# ============================================================================
# EXAMPLE USAGE
# ============================================================================

if __name__ == "__main__":
    # Test payloads
    test_sqli = [
        "1' OR '1'='1",
        "1' UNION SELECT * FROM users --",
        "admin' OR 1=1 --",
        "1' AND SLEEP(5) --",
        "1' UNION SELECT extractvalue(1, concat(0x7e, database())) --",
    ]
    
    test_xss = [
        "<script>alert('XSS')</script>",
        "<img src=x onerror='alert(1)'>",
        "<svg onload=alert('xss')>",
        "<iframe src=javascript:alert(1)>",
    ]
    
    print("üöÄ Advanced Post-RL Payload Validator\n")
    
    # Test SQLi
    print("üìä Testing SQLi Payloads...")
    agent_sqli = AdvancedPostRLAgent(
        attack_type="sqli",
        min_combined_score=0.70,
        device="cpu"
    )
    agent_sqli.process_batch(test_sqli, verbose=True)
    agent_sqli.print_summary()
    agent_sqli.export_production_ready("outputs/sqli_production_ready.json")
    
    # Test XSS
    print("\nüìä Testing XSS Payloads...")
    agent_xss = AdvancedPostRLAgent(
        attack_type="xss",
        min_combined_score=0.70,
        device="cpu"
    )
    agent_xss.process_batch(test_xss, verbose=True)
    agent_xss.print_summary()
    agent_xss.export_production_ready("outputs/xss_production_ready.json")
    
    # Show sample results
    print("\n" + "="*80)
    print("SAMPLE DETAILED RESULTS")
    print("="*80)
    
    if agent_sqli.results:
        r = agent_sqli.results[0]
        print(f"\n[SQLI Sample]")
        print(f"Original: {r.original_payload}")
        print(f"Corrected: {r.corrected_payload}")
        print(f"Production Ready: {r.is_production_ready}")
        print(f"Combined Score: {r.quality_score.combined_score:.4f}")
        print(f"WAF Techniques: {r.waf_evasion.obfuscation_techniques}")
